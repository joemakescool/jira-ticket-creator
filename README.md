# JIRA Ticket Creator

AI-powered JIRA ticket generation with swappable LLM providers.

## Architecture

```
jira-ticket-creator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # React UI components
â”‚   â”‚   â”œâ”€â”€ TicketForm/
â”‚   â”‚   â”œâ”€â”€ TicketPreview/
â”‚   â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ llm/             # LLM abstraction layer
â”‚   â”‚   â”‚   â”œâ”€â”€ providers/   # Concrete implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ LLMProvider.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ LLMFactory.ts
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ ticket/          # Ticket generation logic
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ hooks/               # Custom React hooks
â”‚   â”œâ”€â”€ types/               # TypeScript definitions
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”œâ”€â”€ prompts/             # LLM prompt templates
â”‚   â”œâ”€â”€ config/              # App configuration
â”‚   â””â”€â”€ App.tsx
â”œâ”€â”€ server/                  # Backend API (keeps API keys secure)
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ middleware/
â”‚   â””â”€â”€ index.ts
â”œâ”€â”€ .env.example
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## Key Design Decisions

### 1. LLM Provider Abstraction (Strategy Pattern)

Swap between Claude, GPT, Gemini, or local models without changing business logic:

```typescript
// Usage
const provider = LLMFactory.create('claude');
const ticket = await ticketService.generate(input, provider);

// Swap providers easily
const provider = LLMFactory.create('openai');
const provider = LLMFactory.create('ollama');
```

### 2. Separation of Concerns

- **Components**: Pure UI, no business logic
- **Services**: Business logic, LLM orchestration
- **Hooks**: State management, side effects
- **Prompts**: Versioned, testable prompt templates

### 3. Backend API

API keys stay on the server. The frontend calls your backend, which calls the LLM:

```
[React App] â†’ [Your API] â†’ [LLM Provider]
```

## Getting Started

```bash
# Install dependencies
npm install

# Set up environment
cp .env.example .env
# Add your API keys to .env

# Run development server
npm run dev
```

## Environment Variables

```env
# LLM Providers (add the ones you want to use)
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
GOOGLE_AI_API_KEY=...

# Default provider
DEFAULT_LLM_PROVIDER=claude

# Server
PORT=3001
```

## Supported LLM Providers

| Provider | Model | Status |
|----------|-------|--------|
| Anthropic Claude | claude-sonnet-4-20250514 | âœ… Ready |
| OpenAI | gpt-4o | âœ… Ready |
| Google Gemini | gemini-pro | ðŸ”§ Planned |
| Ollama (local) | llama3, mistral | ðŸ”§ Planned |

## License

MIT
